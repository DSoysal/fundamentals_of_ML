{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE 449 HW-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils.py  \n",
    "Necessary tools for grading and testing <br>\n",
    "Provided by the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "def part1CreateDataset(train_samples=1000, val_samples=100, std=0.4):\n",
    "    # CREATE A RANDOM DATASET\n",
    "\n",
    "    centers = [[1, 1], [1, -1], [-1, -1], [-1, 1]] #center of each class\n",
    "    cluster_std = std # standard deviation of random gaussian samples\n",
    "\n",
    "    x_train, y_train = make_blobs(n_samples=train_samples, centers=centers, n_features=2, cluster_std=cluster_std, shuffle=True)\n",
    "    y_train[y_train==2] = 0 # make this an xor problem\n",
    "    y_train[y_train==3] = 1 # make this an xor problem\n",
    "    y_train = y_train.reshape(-1, 1) #vectorize the ground truth\n",
    "\n",
    "    x_val, y_val = make_blobs(n_samples=val_samples, centers=centers, n_features=2, cluster_std=cluster_std, shuffle=True)\n",
    "    y_val[y_val==2] = 0 # make this an xor problem\n",
    "    y_val[y_val==3] = 1 # make this an xor problem\n",
    "    y_val = y_val.reshape(-1, 1) # vectorize the ground truth\n",
    "\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "def part1PlotBoundary(X, y, nn):\n",
    "\n",
    "    # Plot decision boundary\n",
    "    h = 0.01\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = nn.forward(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, levels=[0, 0.5, 1], colors=['lightcoral', 'lightblue'], alpha=0.5)\n",
    "\n",
    "    # Add contour lines\n",
    "    plt.contour(xx, yy, Z, levels=[0.5], colors='black')\n",
    "\n",
    "    # Plot data points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y.flatten(), cmap=plt.cm.RdYlBu)\n",
    "\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.title('Decision Boundary')\n",
    "    plt.show()\n",
    "\n",
    "# utility function to create performance plots for part 2\n",
    "def part2Plots(out, nmax=64, save_dir='', filename=''):\n",
    "    out = torch.tensor(out).reshape(-1,1,25,25)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid((out.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
    "    fig.savefig(os.path.join(save_dir, filename + '.png'))\n",
    "\n",
    "\n",
    "# utility function to create performance plots for part 3\n",
    "def part3Plots(results, save_dir='', filename='', show_plot=True):\n",
    "    \"\"\"plots multiple performance curves from multiple training results and\n",
    "    saves the resultant plot as a png image\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "\n",
    "    results: list of dictionary objects, each corresponds to\n",
    "    the result of a training and should have the following key-value\n",
    "    items:\n",
    "\n",
    "        'name': string, indicating the user-defined name of the training\n",
    "\n",
    "        'loss_curve': list of floats, indicating the loss at each step\n",
    "\n",
    "        'train_acc_curve': list of floats, indicating the the training accuracy at each step\n",
    "\n",
    "        'val_acc_curve': list of floats indicating the the validation accuracy at each step\n",
    "\n",
    "        'test_acc': float, indicating the best test accuracy\n",
    "\n",
    "        'weights': (not used), 2-D float array, weights of the first hidden layer of the trained MLP\n",
    "\n",
    "    save_dir: string, indicating the path to directory where the plot image is to be saved\n",
    "\n",
    "    filename: string, indicating the name of the image file. Note that .png will be automatically\n",
    "    appended to the filename.\n",
    "\n",
    "    show_plot: bool, whether the figure is to be shown\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "\n",
    "    visualizing the results of the training\n",
    "\n",
    "    # assume the '*_value's are known\n",
    "\n",
    "    >>> result_x = {'name': name_value, 'loss_curve': loss_curve_value,\n",
    "                    'train_acc_curve': train_acc_curve_value,\n",
    "                     'val_acc_curve': val_acc_curve_value,\n",
    "                     'test_acc': test_acc_value}\n",
    "\n",
    "    >>> results = [result_1, ..., result_x, ..., result_N]\n",
    "\n",
    "    >>> part2Plots(results, save_dir=r'some\\location\\to\\save', filename='part2Plots')\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    color_list = ['#0000ff', '#ff0000', '#d2691e', '#ff00ff', '#00ff00', '#000000', '#373788']\n",
    "    style_list = ['-', '--']\n",
    "\n",
    "    num_results = len(results)\n",
    "\n",
    "    plot_curve_args = [{'c': color_list[k],\n",
    "                        'linestyle': style_list[0],\n",
    "                        'linewidth': 2} for k in range(num_results)]\n",
    "\n",
    "    plot_point_args = [{'c': color_list[k],\n",
    "                        'marker': 'o',\n",
    "                        'markersize': 9,\n",
    "                        'markerfacecolor':  color_list[k]} for k in range(num_results)]\n",
    "\n",
    "\n",
    "\n",
    "    font_size = 18\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "\n",
    "    # training loss\n",
    "    ax = axes[0, 0]\n",
    "    ax.set_title('training_loss', loc='left', fontsize=font_size)\n",
    "    for result, args in zip(results, plot_curve_args):\n",
    "        ax.plot(np.arange(1, len(result['loss_curve']) + 1), result['loss_curve'], label=result['name'], **args)\n",
    "        ax.set_xlabel(xlabel='step', fontsize=font_size)\n",
    "        ax.set_ylabel(ylabel='loss', fontsize=font_size)\n",
    "        ax.tick_params(labelsize=12)\n",
    "\n",
    "    # get lines for global legend\n",
    "    lines = ax.get_lines()\n",
    "\n",
    "\n",
    "    # training and validation accuracy\n",
    "    ax = axes[0, 1]\n",
    "    ax.set_title('train_and_val_accuracies', loc='right', fontsize=font_size)\n",
    "    for result, args in zip(results, plot_curve_args):\n",
    "        ax.plot(np.arange(1, len(result['train_acc_curve']) + 1), result['train_acc_curve'], label=result['name'],\n",
    "                **args)\n",
    "        args['linestyle'] = style_list[1]\n",
    "        ax.plot(np.arange(1, len(result['val_acc_curve']) + 1), result['val_acc_curve'], label=result['name'],\n",
    "                **args)\n",
    "        args['linestyle'] = style_list[0]\n",
    "        ax.set_xlabel(xlabel='step', fontsize=font_size)\n",
    "        ax.set_ylabel(ylabel='acc.', fontsize=font_size)\n",
    "        ax.tick_params(labelsize=12)\n",
    "\n",
    "        legend_elements = [Line2D([0], [0], color='k', linestyle=style_list[0], lw=2, label='train.'),\n",
    "                           Line2D([0], [0], color='k', linestyle=style_list[1], lw=2, label='val.')]\n",
    "\n",
    "        ax.legend(fontsize=12, loc='best', handles=legend_elements)\n",
    "\n",
    "    # validation vs training accuracy\n",
    "    ax = axes[1, 1]\n",
    "    ax.set_title('validation_vs_training_accuracy', loc='right', fontsize=font_size)\n",
    "    for result, args in zip(results, plot_curve_args):\n",
    "        ax.plot(result['train_acc_curve'], result['val_acc_curve'], label=result['name'], **args)\n",
    "        ax.set_xlabel(xlabel='training', fontsize=font_size)\n",
    "        ax.set_ylabel(ylabel='validation', fontsize=font_size)\n",
    "        ax.tick_params(labelsize=12)\n",
    "\n",
    "\n",
    "\n",
    "    # test vs training accuracy\n",
    "    ax = axes[1, 0]\n",
    "    ax.set_title('test_vs_training_accuracy', loc='left', fontsize=font_size)\n",
    "    for result, args in zip(results, plot_point_args):\n",
    "        train_acc = result['train_acc_curve'][-1]\n",
    "        test_acc = result['test_acc']\n",
    "        ax.plot(train_acc, test_acc, label=result['name'],  **args)\n",
    "        ax.set_xlabel(xlabel='training', fontsize=font_size)\n",
    "        ax.set_ylabel(ylabel='test', fontsize=font_size)\n",
    "        ax.tick_params(labelsize=12)\n",
    "\n",
    "    # global legend\n",
    "    fig.legend(labels=[line._label for line in lines],\n",
    "               ncol=3, loc=\"upper center\", fontsize=font_size,\n",
    "               handles=lines)\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "\n",
    "    fig.savefig(os.path.join(save_dir, filename + '.png'))\n",
    "\n",
    "# utility function to create performance plots for part 4\n",
    "def part4Plots(results, save_dir='', filename='', show_plot=True):\n",
    "    \"\"\"plots multiple performance curves from multiple training results and\n",
    "    saves the resultant plot as a png image\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "\n",
    "    results: list of dictionary objects, each corresponds to\n",
    "    the result of a training and should have the following key-value\n",
    "    items:\n",
    "\n",
    "        'name': string, indicating the user-defined name of the training\n",
    "\n",
    "        'relu_loss_curve': list of floats, indicating the loss at each step\n",
    "\n",
    "        'sigmoid_loss_curve': list of floats, indicating the loss at each step\n",
    "\n",
    "        'relu_grad_curve': list of floats, indicating the gradient magnitude at each step\n",
    "\n",
    "        'sigmoid_grad_curve': list of floats, indicating the gradient magnitude at each step\n",
    "\n",
    "    save_dir: string, indicating the path to directory where the plot image is to be saved\n",
    "\n",
    "    filename: string, indicating the name of the image file. Note that .png will be automatically\n",
    "    appended to the filename.\n",
    "\n",
    "    show_plot: bool, whether the figure is to be shown\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "\n",
    "    visualizing the results of the training\n",
    "\n",
    "    # assume the '*_value's are known\n",
    "\n",
    "    >>> result_x = {'name': name_value, 'relu_loss_curve': relu_loss_curve_value,\n",
    "                    'sigmoid_loss_curve': sigmoid_loss_curve_value,\n",
    "                     'relu_grad_curve': relu_grad_curve_value}\n",
    "\n",
    "    >>> results = [result_1, ..., result_x, ..., result_N]\n",
    "\n",
    "    >>> part3Plots(results, save_dir=r'some\\location\\to\\save', filename='part3Plots')\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    color_list = ['#0000ff', '#ff0000', '#d2691e', '#ff00ff', '#00ff00', '#000000', '#373788']\n",
    "    style_list = ['-', '--']\n",
    "\n",
    "    num_results = len(results)\n",
    "\n",
    "    relu_curve_args = [{'c': color_list[k],\n",
    "                        'linestyle': style_list[0],\n",
    "                        'linewidth': 2} for k in range(num_results)]\n",
    "\n",
    "    sigmoid_curve_args = [{'c': color_list[k],\n",
    "                        'linestyle': style_list[1],\n",
    "                        'linewidth': 2} for k in range(num_results)]\n",
    "\n",
    "\n",
    "\n",
    "    font_size = 18\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 12))\n",
    "\n",
    "    legend_elements = [Line2D([0], [0], color='k', linestyle=style_list[0], lw=2, label='ReLU'),\n",
    "                       Line2D([0], [0], color='k', linestyle=style_list[1], lw=2, label='Sigmoid')]\n",
    "\n",
    "    # training loss\n",
    "    ax = axes[0]\n",
    "    ax.set_title('training_losses', loc='left', fontsize=font_size)\n",
    "    for result, relu_args, sigmoid_args in zip(results, relu_curve_args, sigmoid_curve_args):\n",
    "        ax.plot(np.arange(1, len(result['relu_loss_curve']) + 1),\n",
    "                result['relu_loss_curve'], label=result['name'], **relu_args)\n",
    "        ax.plot(np.arange(1, len(result['sigmoid_loss_curve']) + 1),\n",
    "                result['sigmoid_loss_curve'], label=result['name'], **sigmoid_args)\n",
    "        ax.set_xlabel(xlabel='step', fontsize=font_size)\n",
    "        ax.set_ylabel(ylabel='loss', fontsize=font_size)\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.legend(loc='upper left', fontsize=12, handles=legend_elements)\n",
    "\n",
    "    # gradient magnitude\n",
    "    ax = axes[1]\n",
    "    ax.set_title('gradient_magnitudes', loc='right', fontsize=font_size)\n",
    "    for result, relu_args, sigmoid_args in zip(results, relu_curve_args, sigmoid_curve_args):\n",
    "        ax.plot(np.arange(1, len(result['relu_grad_curve']) + 1),\n",
    "                result['relu_grad_curve'], label=result['name'], **relu_args)\n",
    "        ax.plot(np.arange(1, len(result['sigmoid_grad_curve']) + 1),\n",
    "                result['sigmoid_grad_curve'], label=result['name'], **sigmoid_args)\n",
    "        ax.set_xlabel(xlabel='step', fontsize=font_size)\n",
    "        ax.set_ylabel(ylabel='|grad_loss|', fontsize=font_size)\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.legend(loc='upper right', fontsize=12, handles=legend_elements)\n",
    "\n",
    "    # global legend\n",
    "    lines = ax.get_lines()[::2]\n",
    "    fig.legend(labels=[line._label for line in lines],\n",
    "               ncol=3, loc=\"upper center\", fontsize=font_size,\n",
    "               handles=lines)\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "\n",
    "    fig.savefig(os.path.join(save_dir, filename + '.png'))\n",
    "\n",
    "# utility function to create performance plots for part 5\n",
    "def part5Plots(result, save_dir='', filename='', show_plot=True):\n",
    "    \"\"\"plots multiple performance curves from multiple training results and\n",
    "    saves the resultant plot as a png image\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "\n",
    "    result: dictionary object, each corresponds to\n",
    "    the result of a training and should have the following key-value\n",
    "    items:\n",
    "\n",
    "        'name': string, indicating the user-defined name of the training\n",
    "\n",
    "        'loss_curve_1': list of floats, indicating the loss with .1 lr at each step\n",
    "\n",
    "        'loss_curve_01': list of floats, indicating the loss with .01 lr at each step\n",
    "\n",
    "        'loss_curve_001': list of floats, indicating the loss with .001 lr at each step\n",
    "\n",
    "        'val_acc_curve_1': list of floats, indicating the val acc with .1 lr at each step\n",
    "\n",
    "        'val_acc_curve_01': list of floats, indicating the val acc with .01 lr at each step\n",
    "\n",
    "        'val_acc_curve_001': list of floats, indicating the val acc with .001 lr at each step\n",
    "\n",
    "    save_dir: string, indicating the path to directory where the plot image is to be saved\n",
    "\n",
    "    filename: string, indicating the name of the image file. Note that .png will be automatically\n",
    "    appended to the filename.\n",
    "\n",
    "    show_plot: bool, whether the figure is to be shown\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "\n",
    "    visualizing the results of the training\n",
    "\n",
    "    # assume the '*_value's are known\n",
    "\n",
    "    >>> result = {'name': name_value, 'loss_curve_1': loss_curve_1_value, ...}\n",
    "\n",
    "    >>> part4Plots(result, save_dir=r'some\\location\\to\\save', filename='part4Plots')\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(result, (list, tuple)):\n",
    "        result = result[0]\n",
    "\n",
    "    color_list = ['#0000ff', '#ff0000', '#d2691e', '#ff00ff', '#00ff00', '#000000', '#373788']\n",
    "    style_list = ['-', '--']\n",
    "\n",
    "    num_curves = 3\n",
    "\n",
    "    plot_args = [{'c': color_list[k],\n",
    "                        'linestyle': style_list[0],\n",
    "                        'linewidth': 2} for k in range(num_curves)]\n",
    "\n",
    "\n",
    "    key_suffixes = ['1', '01', '001']\n",
    "\n",
    "\n",
    "    font_size = 18\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 12))\n",
    "\n",
    "    fig.suptitle('training of <%s> with different learning rates'%result['name'],\n",
    "                 fontsize=font_size, y=0.025)\n",
    "\n",
    "    # training loss and validation accuracy\n",
    "    axes[0].set_title('training_losses', loc='left', fontsize=font_size)\n",
    "    axes[1].set_title('validation_accuracies', loc='right', fontsize=font_size)\n",
    "    for key_suffix, plot_args in zip(key_suffixes, plot_args):\n",
    "\n",
    "        loss_curve = result['loss_curve_' + key_suffix]\n",
    "        acc_curve = result['val_acc_curve_' + key_suffix]\n",
    "        label = 'lr=0.%s'%key_suffix\n",
    "\n",
    "        axes[0].plot(np.arange(1, len(loss_curve) + 1),\n",
    "                     loss_curve, label=label, **plot_args)\n",
    "        axes[0].set_xlabel(xlabel='step', fontsize=font_size)\n",
    "        axes[0].set_ylabel(ylabel='loss', fontsize=font_size)\n",
    "        axes[0].tick_params(labelsize=12)\n",
    "\n",
    "        axes[1].plot(np.arange(1, len(acc_curve) + 1),\n",
    "                     acc_curve, label=label, **plot_args)\n",
    "        axes[1].set_xlabel(xlabel='step', fontsize=font_size)\n",
    "        axes[1].set_ylabel(ylabel='accuracy', fontsize=font_size)\n",
    "        axes[1].tick_params(labelsize=12)\n",
    "\n",
    "\n",
    "    # global legend\n",
    "    lines = axes[0].get_lines()\n",
    "    fig.legend(labels=[line._label for line in lines],\n",
    "               ncol=3, loc=\"upper center\", fontsize=font_size,\n",
    "               handles=lines)\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "\n",
    "    fig.savefig(os.path.join(save_dir, filename + '.png'))\n",
    "\n",
    "# utility function to visualize learned weights\n",
    "def visualizeWeights(weights, save_dir, filename='weigths'):\n",
    "    '''visualizes the weights and saves the visualization as a png image\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    weights : numpy array of size 784 x D where D is the number of weights\n",
    "    save_dir : string, path to directory to save the image\n",
    "    filename : strint, name of the saved image (.png is to be appended automatically)\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    visualizing weights at the input layer of a keras.Model object\n",
    "\n",
    "    # assume classifier is an instance of keras.Model\n",
    "\n",
    "    >>> weights = classifier.trainable_weights[0].numpy()\n",
    "\n",
    "    >>> visualizeWeights(weights, save_dir='some\\location\\to\\save', filename='input_weights')\n",
    "    '''\n",
    "\n",
    "    weights = weights.T\n",
    "\n",
    "    num_weights = weights.shape[-1]\n",
    "\n",
    "    dim = np.ceil(np.sqrt(num_weights)).astype(int)\n",
    "\n",
    "    fig, axes = plt.subplots(dim, dim)\n",
    "\n",
    "    # use global min / max to ensure all weights are shown on the same scale\n",
    "    vmin, vmax = weights.min(), weights.max()\n",
    "    for coef, ax in zip(weights.T, axes[:num_weights].ravel()):\n",
    "        coef = np.squeeze(coef).T if len(weights.shape) > 2 else coef.reshape(28, 28)\n",
    "        ax.matshow(coef, cmap=plt.cm.gray, vmin=.5 * vmin,\n",
    "                   vmax=.5 * vmax)\n",
    "\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig.savefig(os.path.join(save_dir, filename + '.png'))\n",
    "\n",
    "# utility function to visualize dataset\n",
    "def visualizeDataset(images, labels, save_dir, filename='dataset', num_samples_per_class=8):\n",
    "\n",
    "    num_classes = np.max(labels) + 1\n",
    "\n",
    "    fig, axes = plt.subplots(num_classes, num_samples_per_class)\n",
    "\n",
    "    images = (images - np.min(images)) / (np.max(images) - np.min(images))\n",
    "\n",
    "    for r in range(num_classes):\n",
    "        sample_indcs = np.where(labels == r)[0][:num_samples_per_class]\n",
    "        for n in range(num_samples_per_class):\n",
    "            axes[r, n].matshow(images[sample_indcs[n]].reshape(28, 28),\n",
    "                               cmap=plt.cm.gray)\n",
    "            axes[r, n].set_xticks(())\n",
    "            axes[r, n].set_yticks(())\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig.savefig(os.path.join(save_dir, filename + '.png'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
